---
title: 卷积、反卷积图像尺寸计算
date: 2020-03-02 21:58:35
tags:
  - CNN
cover: https://user-images.githubusercontent.com/60562661/75624423-e0cb8600-5bee-11ea-9899-4de640dd2236.png
---

一般在设计深度网络架构时，神经网络中无非也就是卷积层和全连接层，而网络一般会对图像尺寸有限制，卷积改变图像的尺寸比较重要，需要会计算。因此来计算一下卷积和反卷积的尺寸计算。以`pytorch`为例.

## Convolution

```python
torch.nn.Conv2D(in_channels,out_channels,kernel_size,stride,padding,bias)
#以上几个参数比较常用
```

卷积操作后图像计算尺寸为：


$$
W_{out} = \frac {W_{input} - W_{filter} + 2*padding}{stride + 1}
$$

$$
H_{out} = \frac {H_{input} - H_{filter} + 2*padding}{stride + 1}
$$

+ 一般情况下，均为正方形，即`W = H`
+ 如果计算结果不是正数，则向下取整

## Deconvolution

```python
torch.nn.ConvTranspose2D(in_channels, out_channels, kernel_size, stride, padding,  output_padding，bias)
# 其中，padding是输入图片补0个数，output_padding是输出图像补0个数
# 直观上是扩大图片，边上填充0也可以用来扩大图像
```

反卷积图像尺寸计算公式：
$$
W_{out} = (W_{input} - 1)*stride + Padding_{output} - 2*Padding_{input} + W_{Kernelsize}
$$

$$
H_{out} = (H_{input} - 1)*stride + Padding_{output} - 2*Padding_{input} + H_{Kernelsize}
$$

其中，

- $Padding_{output}$ 指的是`ConvTranspose2D`这个函数中的` output_padding ` 参数；
- $Padding_{input}$ 指的是上述函数的`padding` 参数

