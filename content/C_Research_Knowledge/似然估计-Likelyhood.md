---
title: 似然估计-Likelyhood
date: 2020-03-19 22:57:18
cover: https://user-images.githubusercontent.com/60562661/77088382-56cd4b00-6a3f-11ea-819d-927bcfaeb803.jpg
tags:
  - 概率论
---

参考：https://zhuanlan.zhihu.com/p/36824006

## 概率 (Probability) & 似然 (Likelyhood)

概率就是随机事件发生的可能性的度量，根据实验或者已知的模型来计算某种可能性，可以称之为**概率。**

似然则是已经知道数据结果分布，由结果来推测模型的参数，这个过程就是**似然。**

所以这两个过程大概上是相反的。似然更通俗的说就是给定样本$X = x$下参数 $\theta = \theta_1$相对于参数取另外的值$\theta = \theta_2$为真实值的可能性。



## 似然函数

设模型参数为θ，则：
$$
L(\theta|x) = P(X=x|\theta)
$$
也就是说估计θ值使得实验结果X=x。

对于某一实验，我们可能包含多种情况，其中每个实验结果的概率可记为一个集合 ：
$$
P = \{p_1,p_2,p_3,...p_n\} \  (\sum_{i=1}^np_i = 1)
$$
假设做了m次实验，则实验结果出现概率为：
$$
E = \prod_{l=2}^mp_k,\space p_k \in P
$$


## 极大似然估计

似然函数L最大化时就是极大似然估计。极大似然估计因为是连乘，所以一般是取log之后变为求和，然后再去求最大值，具体可以参考文章开始提到的链接中的抓豆子实验，很形象。



## 思考

在深度学习中，用神经网络作分类问题实际上也就是建立了一个模型，这个模型的参数(w)就相当于似然估计中的参数θ，用大量的数据去学习，去调整w，也就是已经知道结果，由结果去估计参数(w),使得取参数w后可以更准确的估计真实数据概率。也就是在做最大似然估计，而最大似然估计已经证明就是最小化交叉熵。

**所以极大似然估计就是根据经验来推断规律。**